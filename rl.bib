@article{le2018deep,
  title={A deep hierarchical reinforcement learning algorithm in partially observable Markov decision processes},
  author={Le, Tuyen P and Vien, Ngo Anh and Chung, TaeChoong},
  journal={Ieee Access},
  volume={6},
  pages={49089--49102},
  year={2018},
  publisher={IEEE}
}


@article{ma2020hierarchical,
  title={Hierarchical reinforcement learning via dynamic subspace search for multi-agent planning},
  author={Ma, Aaron and Ouimet, Michael and Cort{\'e}s, Jorge},
  journal={Autonomous Robots},
  volume={44},
  number={3},
  pages={485--503},
  year={2020},
  publisher={Springer}
}


@article{tang2018hierarchical,
  title={Hierarchical deep multiagent reinforcement learning with temporal abstraction},
  author={Tang, Hongyao and Hao, Jianye and Lv, Tangjie and Chen, Yingfeng and Zhang, Zongzhang and Jia, Hangtian and Ren, Chunxu and Zheng, Yan and Meng, Zhaopeng and Fan, Changjie and others},
  journal={arXiv preprint arXiv:1809.09332},
  year={2018}
}


@article{omidshafiei2017deep,
  title={Deep decentralized multi-task multi-agent reinforcement learning under partial observability},
  author={Omidshafiei, Shayegan and Pazis, Jason and Amato, Christopher and How, Jonathan P and Vian, John},
  journal={arXiv preprint arXiv:1703.06182},
  year={2017}
}


@inproceedings{lanctot2017unified,
  title={A unified game-theoretic approach to multiagent reinforcement learning},
  author={Lanctot, Marc and Zambaldi, Vinicius and Gruslys, Audrunas and Lazaridou, Angeliki and Tuyls, Karl and P{\'e}rolat, Julien and Silver, David and Graepel, Thore},
  booktitle={Advances in neural information processing systems},
  pages={4190--4203},
  year={2017}
}

@inproceedings{iqbal2019actor,
  title={Actor-attention-critic for multi-agent reinforcement learning},
  author={Iqbal, Shariq and Sha, Fei},
  booktitle={International Conference on Machine Learning},
  pages={2961--2970},
  year={2019},
  organization={PMLR}
}


@article{yang2018mean,
  title={Mean field multi-agent reinforcement learning},
  author={Yang, Yaodong and Luo, Rui and Li, Minne and Zhou, Ming and Zhang, Weinan and Wang, Jun},
  journal={arXiv preprint arXiv:1802.05438},
  year={2018}
}


@article{co2018self,
  title={Self-consistent trajectory autoencoder: Hierarchical reinforcement learning with trajectory embeddings},
  author={Co-Reyes, John D and Liu, YuXuan and Gupta, Abhishek and Eysenbach, Benjamin and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1806.02813},
  year={2018}
}


@article{haarnoja2018latent,
  title={Latent space policies for hierarchical reinforcement learning},
  author={Haarnoja, Tuomas and Hartikainen, Kristian and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1804.02808},
  year={2018}
}


@article{florensa2017stochastic,
  title={Stochastic neural networks for hierarchical reinforcement learning},
  author={Florensa, Carlos and Duan, Yan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1704.03012},
  year={2017}
}


@article{nachum2018near,
  title={Near-optimal representation learning for hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
  journal={arXiv preprint arXiv:1810.01257},
  year={2018}
}


@inproceedings{icarte2019learning,
  title={Learning reward machines for partially observable reinforcement learning},
  author={Icarte, Rodrigo Toro and Waldie, Ethan and Klassen, Toryn and Valenzano, Rick and Castro, Margarita and McIlraith, Sheila},
  booktitle={Advances in Neural Information Processing Systems},
  pages={15523--15534},
  year={2019}
}


@article{hausknecht2015deep,
  title={Deep recurrent q-learning for partially observable mdps},
  author={Hausknecht, Matthew and Stone, Peter},
  journal={arXiv preprint arXiv:1507.06527},
  year={2015}
}


@article{heinrich2016deep,
  title={Deep reinforcement learning from self-play in imperfect-information games},
  author={Heinrich, Johannes and Silver, David},
  journal={arXiv preprint arXiv:1603.01121},
  year={2016}
}


@book{krishnamurthy2016partially,
  title={Partially observed Markov decision processes},
  author={Krishnamurthy, Vikram},
  year={2016},
  publisher={Cambridge University Press}
}


@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}